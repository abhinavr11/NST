{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleTransfer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-m5P4avdQ3R",
        "outputId": "4e167aeb-0688-446a-85f2-f7cbaab369a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.12.0+cu113)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.21.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.13.0+cu113)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2022.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install -U sentence-transformers\n",
        "!pip install flask-ngrok\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers.optimization import  Adafactor \n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Combining Text"
      ],
      "metadata": {
        "id": "Y0Y-c9VO7nes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "url = 'https://gitlab.com/shimorina/webnlg-dataset/-/archive/master/webnlg-dataset-master.zip?path=release_v3.0/en/train'\n",
        "urllib.request.urlretrieve(url, 'web.zip')\n",
        "with zipfile.ZipFile('web.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('web')\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "files = glob.glob(\"/content/web/webnlg-dataset-master-release_v3.0-en-train/release_v3.0/en/train/**/*.xml\", recursive=True)\n",
        "triple_re=re.compile('(\\d)triples')\n",
        "data_dct={}\n",
        "for file in files:\n",
        "    tree = ET.parse(file)\n",
        "    root = tree.getroot()\n",
        "    triples_num=int(triple_re.findall(file)[0])\n",
        "    for sub_root in root:\n",
        "        for ss_root in sub_root:\n",
        "            strutured_master=[]\n",
        "            unstructured=[]\n",
        "            for entry in ss_root:\n",
        "                unstructured.append(entry.text)\n",
        "                strutured=[triple.text for triple in entry]\n",
        "                strutured_master.extend(strutured)\n",
        "            unstructured=[i for i in unstructured if i.replace('\\n','').strip()!='' ]\n",
        "            strutured_master=strutured_master[-triples_num:]\n",
        "            strutured_master_str=(' && ').join(strutured_master)\n",
        "            data_dct[strutured_master_str]=unstructured\n",
        "mdata_dct={\"prefix\":[], \"input_text\":[], \"target_text\":[]}\n",
        "for st,unst in data_dct.items():\n",
        "    for i in unst:\n",
        "        mdata_dct['prefix'].append('webNLG')\n",
        "        mdata_dct['input_text'].append(st)\n",
        "        mdata_dct['target_text'].append(i)\n",
        "\n",
        "\n",
        "df=pd.DataFrame(mdata_dct)\n",
        "df.to_csv('webNLG2020_train.csv')\n",
        "\n",
        "train_df=pd.read_csv('webNLG2020_train.csv', index_col=[0])\n",
        "\n",
        "train_df=train_df.iloc[  :35000,:]\n",
        "train_df=train_df.sample(frac = 1)\n",
        "batch_size=8\n",
        "num_of_batches=len(train_df)/batch_size\n",
        "num_of_epochs=4\n",
        "num_of_batches=int(num_of_batches)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    dev = torch.device(\"cuda:0\") \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    dev = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base', return_dict=True)\n",
        "#moving the model to device(GPU/CPU)\n",
        "model.to(dev)\n",
        "\n",
        "\n",
        "optimizer = Adafactor(\n",
        "    model.parameters(),\n",
        "    lr=1e-3,\n",
        "    eps=(1e-30, 1e-3),\n",
        "    clip_threshold=1.0,\n",
        "    decay_rate=-0.8,\n",
        "    beta1=None,\n",
        "    weight_decay=0.0,\n",
        "    relative_step=False,\n",
        "    scale_parameter=False,\n",
        "    warmup_init=False\n",
        ")\n",
        "\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def progress(loss,value, max=100):\n",
        "    return HTML(\"\"\" Batch loss :{loss}\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(loss=loss,value=value, max=max))\n",
        "num_of_epochs=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQIlRGqHG-sy",
        "outputId": "d31275e8-bff2-48a5-bfb0-64365e6db973"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on the GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################################\n",
        "#Sets the module in training mode\n",
        "model.train()\n",
        "\n",
        "loss_per_10_steps=[]\n",
        "for epoch in range(1,num_of_epochs+1):\n",
        "  print('Running epoch: {}'.format(epoch))\n",
        "  \n",
        "  running_loss=0\n",
        "\n",
        "  out = display(progress(1, num_of_batches+1), display_id=True)\n",
        "  for i in range(num_of_batches):\n",
        "    inputbatch=[]\n",
        "    labelbatch=[]\n",
        "    new_df=train_df[i*batch_size:i*batch_size+batch_size]\n",
        "    for indx,row in new_df.iterrows():\n",
        "      input = 'WebNLG: '+row['input_text']+'</s>' \n",
        "      labels = row['target_text']+'</s>'   \n",
        "      inputbatch.append(input)\n",
        "      labelbatch.append(labels)\n",
        "    inputbatch=tokenizer.batch_encode_plus(inputbatch,padding=True,max_length=400,return_tensors='pt')[\"input_ids\"]\n",
        "    labelbatch=tokenizer.batch_encode_plus(labelbatch,padding=True,max_length=400,return_tensors=\"pt\") [\"input_ids\"]\n",
        "    inputbatch=inputbatch.to(dev)\n",
        "    labelbatch=labelbatch.to(dev)\n",
        "\n",
        "    # clear out the gradients of all Variables \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward propogation\n",
        "    outputs = model(input_ids=inputbatch, labels=labelbatch)\n",
        "    loss = outputs.loss\n",
        "    loss_num=loss.item()\n",
        "    logits = outputs.logits\n",
        "    running_loss+=loss_num\n",
        "    if i%10 ==0:      \n",
        "      loss_per_10_steps.append(loss_num)\n",
        "    out.update(progress(loss_num,i, num_of_batches+1))\n",
        "\n",
        "    # calculating the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    #updating the params\n",
        "    optimizer.step()\n",
        "    \n",
        "  running_loss=running_loss/int(num_of_batches)\n",
        "  print('Epoch: {} , Running loss: {}'.format(epoch,running_loss))\n",
        "#################################################################################\n",
        "\n",
        "\n",
        "model.eval()\n",
        "input_ids = tokenizer.encode(\"WebNLG: sidharth | hometown | Delhi && sidharth | play |  football </s>\", return_tensors=\"pt\")  # Batch size 1\n",
        "input_ids=input_ids.to(dev)\n",
        "outputs = model.generate(input_ids)\n",
        "tokenizer.decode(outputs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "-hMqbsEW7oEw",
        "outputId": "a18b0eec-6b7d-43f4-b865-8faa7f7d0547"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running epoch: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " Batch loss :0.5402065515518188\n",
              "        <progress\n",
              "            value='4374'\n",
              "            max='4376',\n",
              "            style='width: 100%'\n",
              "        >\n",
              "            4374\n",
              "        </progress>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 , Running loss: 0.4988790895019259\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad> Sidharth plays football for the city of Delhi.</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/Projects/NST/generative_model/model.pt' \n",
        "#torch.save(model, PATH)\n",
        "model = torch.load(PATH)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "ZPBF6yxF7oP8"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For POS tags"
      ],
      "metadata": {
        "id": "kkRuj7VYCLDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('tagsets')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5X7cT13fGz8",
        "outputId": "61cd8613-6ee6-48a2-ba6e-666837f4716b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Package tagsets is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Similarity"
      ],
      "metadata": {
        "id": "miurHpeICH5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from scipy import spatial\n",
        "#sentences = [\"That is a happy person\", \"That is a very happy person\"]\n",
        "file1 = open('sens.txt', 'r')\n",
        "Lines = file1.readlines()\n",
        "data = []\n",
        "for line in Lines:\n",
        "    if len(line)< 10:\n",
        "      continue\n",
        "    data.append(line.strip())\n",
        "\n",
        "modelEm = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v1')\n",
        "embeddings = modelEm.encode(data)\n",
        "#print(embeddings)\n"
      ],
      "metadata": {
        "id": "rOsNZjZbxJnj"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6IR81YjxMlk",
        "outputId": "38ddcdbf-7447-4617-beee-dc8c51937c3c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1944, 384)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Functions"
      ],
      "metadata": {
        "id": "qchluwLx6OSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getSimilarity(embd1,embd2):\n",
        "  return 1 - spatial.distance.cosine(embd1, embd2)\n",
        "\n",
        "def findSimilarSen(input_sen):\n",
        "  embd = modelEm.encode(input_sen)\n",
        "  idx = 0\n",
        "  max_similarity = 0\n",
        "  \n",
        "  for i,embedding in enumerate(embeddings):\n",
        "    val = getSimilarity(embd,embedding)\n",
        "    if val > max_similarity:\n",
        "      max_similarity = val\n",
        "      idx = i\n",
        "  return data[i],max_similarity\n",
        "\n",
        "def transform(input_sen):\n",
        "  simSen,sim = findSimilarSen(input_sen)\n",
        "\n",
        "  if sim < .5:\n",
        "    return input_sen\n",
        "\n",
        "  JJ = None\n",
        "  isentence = word_tokenize(input_sen)\n",
        "  ssentence = word_tokenize(simSen)\n",
        "\n",
        "  \n",
        "  for tup in nltk.pos_tag(ssentence):\n",
        "    if tup[1][:2] == 'JJ':\n",
        "      JJ = tup[0]\n",
        "\n",
        "  if JJ is None:\n",
        "    return input_sen\n",
        "  \n",
        "  taggedSen = []\n",
        "  for tup in nltk.pos_tag(isentence):\n",
        "    if tup[1][:2] == 'JJ':\n",
        "      taggedSen.append(JJ)\n",
        "    if tup[1][:2] == 'VB' or tup[1][:2] == 'DT':\n",
        "      continue\n",
        "    else:\n",
        "      taggedSen.append(tup[0]) \n",
        "  #print('WebNLG: '+' | '.join(taggedSen)+'</s>')\n",
        "  input_ids = tokenizer.encode('WebNLG: '+' | '.join(taggedSen)+'</s>', return_tensors=\"pt\")  # Batch size 1\n",
        "  input_ids=input_ids.to(dev)\n",
        "  outputs = model.generate(input_ids)\n",
        "  return tokenizer.decode(outputs[0])\n"
      ],
      "metadata": {
        "id": "NJOkO0RjCBkl"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hosting"
      ],
      "metadata": {
        "id": "03oQBVt8DU9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, jsonify, request, render_template\n",
        "from bs4 import BeautifulSoup\n",
        "#from model import ChatBot\n",
        "from model1 import *\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "import json \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "  \n",
        "\n",
        "if __name__=='__main__':\n",
        "    pass\n",
        "\n",
        "    \n",
        "# app\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app) \n",
        "# routes\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "    \n",
        "@app.route('/', methods=['POST'])\n",
        "\n",
        "def predict():\n",
        "    # chatbot = ChatBot()\n",
        "    data = request.get_json(force=True)\n",
        "    print(data)\n",
        "    #reply = chatbot.get_reply(data['message'])\n",
        "    msg = transform(data['message'])\n",
        "    msg = BeautifulSoup(msg, \"lxml\").text\n",
        "    reply = generate_res(msg)\n",
        "\n",
        "    #bodyFat = predictBodyFat(np.asarray(data['raw_img']).astype(np.uint8))\n",
        "    print(\"Message: \",msg)\n",
        "    print(\"Reply: \",reply)\n",
        "    # send back to browser\n",
        "    \n",
        "    # return data \n",
        "    return jsonify(results=[reply,msg])\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qCjZ5FhDVni",
        "outputId": "4a94bc45-63c7-4eee-d083-bc12086b0556"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://2c6f-34-86-134-116.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n",
            "{'message': 'Hi, how are you ?'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [07/Aug/2022 11:39:45] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message:  Hi, how are you ?\n",
            "Reply:  I'm good, you?\n",
            "{'message': 'The pizza was very bad'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [07/Aug/2022 11:39:55] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message:   The pizza is a dish that is a bad food.\n",
            "Reply:  I think you mean bad pizza.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example\n",
        "transform(' The pizza is very bad')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "yhwFT7LXFOZz",
        "outputId": "c00ac83d-c6f8-4576-d342-d1f3cc4e20fd"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WebNLG: pizza | very | next | bad</s>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad> The pizza is a dish that is a bad food.</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "10rC9Ptd_Hvk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}